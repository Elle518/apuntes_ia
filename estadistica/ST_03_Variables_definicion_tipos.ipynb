{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div style=\"display: flex; justify-content: space-between;\">\n",
       "    <div style=\"text-align: center; flex-grow: 1;\">14-11-2023</div>\n",
       "    <div><em>ESTADÍSTICA</em></div>\n",
       "</div>\n",
       "<hr>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "current_date = datetime.now().strftime('%d-%m-%Y')\n",
    "html_content = f\"\"\"\n",
    "<div style=\"display: flex; justify-content: space-between;\">\n",
    "    <div style=\"text-align: center; flex-grow: 1;\">{current_date}</div>\n",
    "    <div><em>ESTADÍSTICA</em></div>\n",
    "</div>\n",
    "<hr>\n",
    "\"\"\"\n",
    "\n",
    "display(HTML(html_content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables\n",
    "\n",
    "La definición de _**variable**_ cambia según el contexto. Por lo general, se representan con una letra y a su vez representan un valor numérico. En álgebra, una variable representa un valor desconocido que necesitamos encontrar. En las funciones y ecuaciones matemáticas, ingresaremos sus valores para calcular la salida. En una ecuación, un coeficiente es un valor fijo por el cual multiplicamos la variable.\n",
    "\n",
    "<center><img src=\"img/equation.png\" width=\"200\"></center>\n",
    "<center><caption><em>Figura 1. Variables</em></caption></center>\n",
    "<br>\n",
    "\n",
    "En estadística, una variable es una característica de interés que medimos, registramos y analizamos, es una característica de los individuos objeto de nuestro estudio. Los estadísticos las describen definiendo el tipo de información que registran y su papel en un experimento o estudio. Una vez que se ha decidido la población o muestra objeto de estudio, escogeremos las variables que conviene estudiar.\n",
    "\n",
    "Las variables registran diferentes tipos de información, y los estadísticos han ideado varios métodos para categorizar las variables y permitirnos comprender así sus diferencias. A continuación, se presentan varias formas clave de agruparlas en función de la información que registran."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cuantitativas vs categóricas\n",
    "\n",
    "Las _**variables cuantitativas**_ registran cifras y cantidades. Por ejemplo, usamos 15,7 litros de gasolina en nuestro último viaje por carretera. Caminamos 11.353 pasos ayer. La planta creció 5,6 cm en una semana. Cada uno de estos ejemplos cuantifica una característica.\n",
    "\n",
    "Las _**variables categóricas**_ definen grupos en los datos. Con frecuencia, utilizaremos un lenguaje descriptivo para estos grupos. Por ejemplo, el estado civil, la carrera universitaria, el tipo de ficción (drama, comedia, ciencia ficción, etc.) y el estilo arquitectónico son todos categóricos y forman grupos en los datos.\n",
    "\n",
    "En un experimento, la condición de tratamiento _(treatment condition)_ es una variable categórica que conforma los grupos experimentales. En un experimento de fertilización de plantas, la condición de tratamiento divide los especímenes en el grupo de control y otros grupos según el tipo de fertilizante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Discretas vs. continuas\n",
    "\n",
    "Cuando tenemos una variable cuantitativa, puede ser discreta o continua. En términos generales, la diferencia entre los dos es la siguiente:\n",
    "\n",
    "* Contamos datos discretos\n",
    "* Medimos datos continuos\n",
    "\n",
    "Las _**variables discretas**_ solo pueden tomar valores específicos que no se pueden subdividir. Con frecuencia, los datos discretos son valores que contamos y, en consecuencia, son enteros no negativos. Por ejemplo, podemos contar la cantidad de personas que viven en un hogar y la cantidad de pasos por día.\n",
    "\n",
    "Las _**variables continuas**_ pueden asumir cualquier valor y podemos dividirlas significativamente en partes más pequeñas, como valores fraccionarios y decimales. Teóricamente, los datos continuos tienen valores infinitos entre dos valores cualesquiera. Por lo general, se miden usando una escala.\n",
    "\n",
    "Por ejemplo, tenemos datos continuos al medir peso, altura, longitud, tiempo y temperatura.\n",
    "\n",
    "Para ampliar más información consultar: `ST_04_Tipos_de_datos_en_ML.ipynb` y `ST_05_Escalas_medida.ipynb`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables aleatorias\n",
    "\n",
    "En estadística, la mayoría de los datos que analizamos son _**variables aleatorias**_, que son funciones que describen todos los valores que ocurren durante una serie de eventos o experimentos aleatorios.\n",
    "\n",
    "Pueden representar datos categóricos, discretos y continuos. Los ejemplos incluyen lo siguiente:\n",
    "\n",
    "* Lanzar monedas o tirar dados y registrar los resultados.\n",
    "* Extraer una muestra aleatoria y medir alturas.\n",
    "* Realizar un experimento de fertilización y registrar el crecimiento de las plantas.\n",
    "\n",
    "En los ejemplos anteriores, un evento proporciona un único valor. Sin embargo, una variable aleatoria comprende todo el conjunto de valores posibles en su espacio muestral.\n",
    "\n",
    "Para las variables aleatorias, los estadísticos evalúan con frecuencia la distribución de los posibles valores, incluida la tendencia central, la dispersión y la asimetría. Además, las funciones de distribución de probabilidad describen la probabilidad de obtener valores particulares. Todas estas propiedades brindan información vital sobre el atributo que estamos estudiando."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables dependientes e independientes\n",
    "\n",
    "Como hemos comentado, una variable es una propiedad que puede contener múltiples valores. Las variables independientes y las variables dependientes son los dos tipos fundamentales de variables en el modelado estadístico y los diseños experimentales. Los analistas utilizan estos métodos para comprender las relaciones entre las variables y estimar el tamaño del efecto que tiene una variable sobre otra.\n",
    "\n",
    "Las _**variables independientes**_ son las que incluimos en el modelo para explicar o predecir cambios en la variable dependiente. En este contexto, independiente indica que las otras variables del modelo no las influyen.\n",
    "\n",
    "Las variables independientes también se conocen como predictores, factores, características, variables explicativas o variables de entrada. En notación, los estadísticos comúnmente las denotan usando $X$. En los gráficos, los analistas colocan las variables independientes en el eje horizontal o $X$.\n",
    "\n",
    "Por ejemplo, en un estudio de crecimiento de plantas, las variables independientes podrían ser la humedad del suelo (continua) y el tipo de fertilizante (categórica).\n",
    "\n",
    "Los modelos estadísticos estimarán los tamaños del efecto para las variables independientes. Determinar qué variables independientes incluir en un modelo estadístico se conoce como _**especificación del modelo**_. Ese proceso implica una investigación profunda y muchas consideraciones teóricas, estadísticas y de áreas temáticas. En su nivel más básico, querremos incluir los predictores que estamos evaluando específicamente en el estudio y las variables de confusión que sesgarán los resultados si no las agregamos.\n",
    "\n",
    "En un experimento, se mide una variable de resultado de interés. La _**variable dependiente**_ es la que deseamos explicar o predecir utilizando el modelo. Los valores de esta variable dependen de otras variables. También se conoce como variable de salida o resultado. Los estadísticos comúnmente los denotan usando una $Y$. Tradicionalmente, los gráficos colocan las variables dependientes en el eje vertical o $Y$.\n",
    "\n",
    "En el ejemplo del estudio del crecimiento de las plantas, la medida del crecimiento de las plantas sería la variable dependiente donde queremos determinar qué es lo que la afecta.\n",
    "\n",
    "El valor de la variable dependiente depende de las variables independiente. Si $Y$ depende de $X$, entonces $Y$ es la variable dependiente. Tengamos en cuenta que una variable puede ser una variable independiente en un estudio pero una variable dependiente en otro, depende del contexto.\n",
    "\n",
    "<center><img src=\"img/independent-and-dependent-variable.png\" width=\"600\"></center>\n",
    "<center><caption><em>Figura 2. Variable dependiente vs independientes</em></caption></center>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables de control\n",
    "\n",
    "Las _**variables de control**_ no son el foco principal de la investigación, pero son propiedades que los investigadores deben monitorear porque pueden influir en el resultado. No incorporarlas en un estudio puede sesgar los hallazgos. Para evitar este sesgo, los científicos pueden mantener constantes estas características durante el estudio o dejar que varíen e incluirlas en sus modelos para controlarlas estadísticamente.\n",
    "\n",
    "Así, las variables de control, también conocidas como variables controladas, son propiedades que los investigadores mantienen constantes para todas las observaciones de un experimento. Aunque estas variables no son el objetivo principal de la investigación, mantener sus valores constantes ayuda al estudio a establecer las verdaderas relaciones entre las variables independientes y dependiente. Las variables de control son diferentes de los grupos de control.\n",
    "\n",
    "En la ciencia, los investigadores evalúan los efectos que las variables independientes tienen sobre la variable dependiente. Sin embargo, otras variables también pueden afectar al resultado. Si los científicos no controlan estas otras variables, pueden distorsionar los resultados primarios de interés. En otras palabras, si no se controlan, esos otros factores se convierten en factores de confusión que pueden sesgar los resultados. Las variables no controladas pueden ser las responsables de los cambios en los resultados más que el tratamiento o las variables experimentales. En consecuencia, los investigadores controlan los valores de estas otras variables.\n",
    "\n",
    "Supongamos que estamos realizando un experimento con diferentes tipos de fertilizantes y el crecimiento de las plantas. Estas son nuestras principales variables de interés. Sin embargo, también sabemos que la humedad del suelo, la luz solar y la temperatura afecten al crecimiento de las plantas. Si no mantenemos estas variables constantes para todas las observaciones, podrían explicar las diferencias de crecimiento de las plantas que observamos.\n",
    "\n",
    "En consecuencia, la humedad, la luz solar y la temperatura son variables de control esenciales para el estudio. Estas variables pueden controlarse manteniendo sus valores constantes para todas las observaciones del experimento. De este modo, si se observan diferencias en el crecimiento de las plantas, podemos estar más seguros de que los fertilizantes las causaron.\n",
    "\n",
    "Cuando los investigadores utilizan variables de control, deben identificarlas, registrar sus valores e incluir los detalles en su informe. Este proceso ayuda a otros investigadores a entender y replicar los resultados.\n",
    "\n",
    "Al controlar las variables, se aumenta la validez interna de la investigación. La validez interna es el grado de confianza en que existe una relación causal entre el tratamiento y la diferencia en los resultados. En otras palabras, ¿qué probabilidad hay de que el tratamiento haya causado las diferencias observadas? ¿Son correctas las conclusiones del investigador? O bien, ¿pueden atribuirse los cambios en el resultado a otras causas?\n",
    "\n",
    "Si las variables relevantes no están controladas, es posible que tengamos que atribuir los cambios a factores de confusión en lugar de al tratamiento. Las variables de control reducen el impacto de las variables de confusión.\n",
    "\n",
    "Los científicos pueden controlar las variables mediante varios métodos. En algunos casos, las variables pueden controlarse directamente. Por ejemplo, los investigadores pueden controlar las condiciones de cultivo para el experimento con fertilizantes. O utilizar procedimientos y procesos estandarizados para todos los sujetos para reducir otras fuentes de variación. Estos esfuerzos intentan eliminar todas las diferencias entre los grupos de tratamiento y de control que no sean los propios tratamientos.\n",
    "\n",
    "Sin embargo, a veces eso no es posible. Afortunadamente, existen otros enfoques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Asignación aleatoria\n",
    "\n",
    "En los experimentos reales, los investigadores controlan las condiciones experimentales asignando a cada sujeto a un grupo de tratamiento o de control.\n",
    "\n",
    "En algunos experimentos, puede haber demasiadas variables que controlar. Además, es posible que los investigadores ni siquiera conozcan todas las posibles variables de confusión. En estos casos, pueden asignar aleatoriamente a los sujetos a los grupos experimentales.\n",
    "\n",
    "Este proceso controla las variables promediando todos los rasgos en los grupos experimentales, haciéndolos aproximadamente equivalentes cuando comienza el experimento. La aleatoriedad ayuda a evitar cualquier diferencia sistemática entre los grupos experimentales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Control estadístico\n",
    "\n",
    "Las variables controladas directamente y la asignación aleatoria son métodos que igualan los grupos experimentales. Sin embargo, no siempre son factibles. En algunos casos, hay demasiadas variables que controlar. En otras situaciones, la asignación aleatoria podría no ser posible, como por ejemplo a la hora de asignar aleatoriamente a personas a grupos de fumadores y no fumadores.\n",
    "\n",
    "Afortunadamente existen técnicas estadísticas, como el análisis de regresión múltiple, que no equilibran los grupos sino que utilizan un modelo que controla estadísticamente las variables. El modelo tiene en cuenta las variables de confusión.\n",
    "\n",
    "En el análisis de regresión múltiple, la inclusión de una variable en el modelo la mantiene constante mientras la variable de tratamiento fluctúa. Este proceso permite aislar el papel del tratamiento mientras se tienen en cuenta los factores de confusión. También podemos utilizar ANOVA y ANCOVA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables de confusión\n",
    "\n",
    "Un _**factor de confusión**_ o una _**variable de confusión**_ es una variable extraña, no prevista o contemplada en la investigación, que puede alterar la relación entre dos variables que son objeto de interés y que, por lo tanto, puede afectar a los juicios de causalidad que hacen los investigadores a partir de la observación de su asociación.\n",
    "\n",
    "Si, en el contexto de una investigación que tenga como objetivo poner a prueba una relación de causalidad, observamos una asociación entre una variable independiente, también llamada variable predictora o explicativa, y una variable dependiente, también conocida como variable resultado o explicada, una tercera variable sería un factor de confusión si su incorporación al análisis comportara el incremento, el decrecimiento, la desaparición o, incluso, la inversión de su relación.\n",
    "\n",
    "Para hacerlo, el potencial factor de confusión tendría que cumplir necesariamente la condición de estar asociado tanto con la variable dependiente como con la independiente, de manera que su efecto o contribución específica en relación con la variable dependiente resultaría indistinguible del que tendría la variable independiente.\n",
    "\n",
    "Es precisamente por esta razón que, como todos los investigadores deberían tener siempre presente en su práctica, a pesar de que la determinación de una relación de causalidad implica la observación de una asociación entre dos variables, la mera evidencia de esta asociación desde el punto de vista estadístico no implica, necesariamente, la existencia de una relación causal (_\"correlation does not imply causation\"_). \n",
    "\n",
    "Un ejemplo clásico en el que interviene una variable de confusión es el fenómenos de la paradoja de Simpson (`ST_06_Paradoja_Simpson.ipynb`), donde la omisión de una variable de confusión en el diseño de una investigación hace que el análisis agregado conduzca a una conclusión sesgada.\n",
    "\n",
    "En el ejemplo de la Universidad de Berkley, al no disponer de los datos originales desagregados para la totalidad de los departamentos, no es posible ir más allá de una explicación intuitiva y mostrar, mediante las pruebas estadísticas oportunas, de qué manera el departamento actúa en este caso como un factor de confusión y, por lo tanto, cumple la condición necesaria de estar asociado tanto al género de los candidatos (variable independiente) como a su aceptación final (variable dependiente).\n",
    "\n",
    "En cambio, podemos ilustrar este requerimiento con un ejemplo ficticio que, además, nos permitirá poner de manifiesto cómo la incorporación de un factor de confusión al análisis no solo puede alterar la relación observada entre dos variables, sino que, incluso, puede hacer evidente una relación que ni siquiera había sido observada inicialmente.\n",
    "\n",
    "Imaginemos una universidad ficticia formada, para simplificar el análisis, únicamente por dos departamentos. Teniendo en cuenta el conjunto global de solicitudes, supongamos que se presentaron un total de 1.000 candidatos, de los cuales 450 habrían sido hombres y 550 mujeres. Supongamos también que de estos candidatos finalmente un 60 %, tanto de hombres como de mujeres, habrían sido aceptados para iniciar sus estudios. La siguiente tabla recoge estos datos, desagregando las candidaturas admitidas y rechazadas en función del departamento escogido y del género de los solicitantes.\n",
    "\n",
    "<center><img src=\"img/vc_table_1.png\" width=\"600\"></center>\n",
    "<center><caption><em>Figura 3. Resolución solicitudes de acceso según departamento y género</em></caption></center>\n",
    "<br>\n",
    "\n",
    "En este caso, teniendo en cuenta que la tasa global de aceptación en el conjunto de los dos departamentos habría sido del 60 %, tanto para los hombres como para las mujeres, el hecho de que no se observe ninguna diferencia sería una evidencia en contra de la existencia de una discriminación por razón de género. Si utilizamos los datos totales que se presentan en la última fila para construir una tabla de contingencia, el análisis de su asociación nos permite afirmar que, al menos de manera agregada, no existe ninguna relación entre el género de los candidatos y su aceptación en esta universidad ficticia ($\\chi^2$ = 0, df = 1, p = 1). Como es natural, tratándose de dos variables totalmente independientes entre sí, la intensidad o magnitud de su relación es nula (V de Cramér = 0).\n",
    "\n",
    "Nuestra universidad ficticia no mostraría ninguna preferencia, ni por los hombres ni por las mujeres, en la resolución de las solicitudes de acceso de los estudiantes a sus programas. Pero, si en lugar de hacer un análisis agregado nos fijamos en los datos que corresponden a cada uno de los dos departamentos, la situación que nos encontramos resulta muy diferente.\n",
    "\n",
    "Teniendo en cuenta sus respectivas solicitudes, al departamento A se habrían presentado 200 hombres y 100 mujeres, de los cuales habrían sido finalmente aceptados un 40 % y un 20 %, respectivamente. En un sentido similar, al departamento B se habrían presentado 250 hombres y 450 mujeres, de los cuales habrían sido aceptados, respectivamente, un 76 % y aproximadamente un 69 %.\n",
    "\n",
    "Una diferencia entre hombres y mujeres de 20 puntos en el departamento A y de 17 puntos en el departamento B sería una evidencia clara a favor de la existencia de una discriminación por razón de género. Los dos departamentos de esta universidad preferirían, en realidad, a los hombres antes que a las mujeres como estudiantes de sus programas.\n",
    "\n",
    "De hecho, si utilizamos los datos que se presentan en la primera y en la segunda fila para construir dos tablas de contingencia separadas, el análisis de la asociación nos permitiría afirmar que existe una relación estadísticamente significativa entre el género de los candidatos y su aceptación a favor de los hombres, tanto en el departamento A ($\\chi^2$ = 12, df = 1, p < 0,001) como en el departamento B ($\\chi^2$ = 3,98, df = 1, p < 0,05). Aun así, la intensidad o magnitud de esta relación es más importante en el caso del primer departamento (V de Cramér = 0,2) que en el segundo (V de Cramér = 0,08).\n",
    "\n",
    "En este sentido, el análisis de los datos desagregados para cada uno de los dos departamentos de nuestra universidad ficticia sugiere la existencia de un factor de confusión que debería ser tenido en cuenta.\n",
    "\n",
    "A continuación presentamos dos tablas de contingencia construidas a partir de los mismos datos, que nos permitirán determinar hasta qué punto el departamento cumple la condición necesaria exigida a cualquier factor o variable de confusión y que, por lo tanto, está efectivamente relacionado tanto con la aceptación de los candidatos, es decir, la variable dependiente, como con su género, es decir, la variable independiente.\n",
    "\n",
    "<center><img src=\"img/vc_table_2.png\" width=\"600\"></center>\n",
    "<center><caption><em>Figura 4. Datos admisión según departamento</em></caption></center>\n",
    "<br>\n",
    "\n",
    "Por un lado, agrupando todos los candidatos independientemente de su género, la tabla anterior presenta los datos de admisión según el departamento escogido y muestra una importante diferencia en su comportamiento en relación con la aceptación de los estudiantes que se habrían presentado. Así, el departamento A sería el que más dificultades habría puesto a los estudiantes, de forma que habría resuelto favorablemente solo un tercio (33,33 %) de sus 300 solicitudes. En comparación, habría sido más fácil acceder al departamento B, que habría aceptado algo más de dos tercios (71,43 %) de las 700 solicitudes que habría valorado.\n",
    "\n",
    "<center><img src=\"img/vc_table_3.png\" width=\"600\"></center>\n",
    "<center><caption><em>Figura 5. Datos admisión según género</em></caption></center>\n",
    "<br>\n",
    "\n",
    "Por otro lado, agrupando ahora todos los candidatos independientemente de su aceptación final en los departamentos, la tabla anterior presenta las solicitudes de acceso según el género de los candidatos y muestra también una importante diferencia en su comportamiento en relación con la elección del departamento para presentar sus candidaturas. Así, el departamento A sería el que menos mujeres habrían escogido, de forma que sus 100 candidatas solo suponen un tercio (33,33 %) de las solicitudes que habría valorado. En cambio, en el departamento B se habrían presentado más mujeres, y habría valorado 450 candidatas que representan casi dos tercios (64,29 %) de sus solicitudes.\n",
    "\n",
    "En este sentido, utilizando estas dos tablas de contingencia para analizar la asociación del departamento con las dos variables, podemos afirmar que existe una relación estadísticamente significativa tanto con la aceptación final de los candidatos ($\\chi^2$ = 126,98, df = 1, p < 0,001) como con su género ($\\chi^2$ = 81,29, df = 1, p < 0,001) que, además, resulta comparativamente de una intensidad o magnitud más importante en el primer caso (V de Cramér = 0,36 y 0,29, respectivamente). En efecto, tal como sugería la inspección preliminar de los datos desagregados, el departamento estaría actuando como factor o variable de confusión y, por lo tanto, el análisis agregado en el caso de nuestra universidad ficticia nos habría llevado a una conclusión sesgada.\n",
    "\n",
    "La lección que podemos extraer del caso de la discriminación de género de la Universidad de Berkeley, como ejemplo clásico de la paradoja de Simpson, es que la existencia de potenciales factores de confusión no considerados en el análisis es una de las amenazas más importantes para los investigadores que se plantean hacer juicios de causalidad a partir de la observación de asociaciones entre sus variables.\n",
    "\n",
    "Como hemos podido ver, la incorporación de estos factores al análisis puede comportar el incremento, el decrecimiento, la desaparición o, incluso, la inversión de las relaciones observadas, de forma que la mera evidencia de la existencia de una asociación entre dos variables no implica, necesariamente, que esta relación sea de naturaleza causal.\n",
    "\n",
    "De hecho, la incorporación de un factor de confusión al análisis no solo puede alterar la relación observada entre dos variables, sino que también puede hacer evidente una relación que, como en el caso de nuestra universidad ficticia, ni siquiera había sido inicialmente observada. Por esta razón, sea cual sea el tipo de investigación, es obligación de los investigadores considerar la eventual influencia de cualquier tipo de variable extraña que pudiera interferir y, por lo tanto, examinar exhaustivamente las relaciones entre sus variables y los potenciales factores de confusión relevantes en el contexto particular de sus estudios.\n",
    "\n",
    "En este sentido, es importante tener presente que la capacidad de los investigadores para establecer inferencias causales a partir del análisis de sus datos está muy relacionada con la naturaleza del diseño de la investigación empleado para obtenerlas. Si entendemos el análisis estadístico como la culminación de un complejo proceso de planificación a través del cual se lleva a cabo cualquier investigación cuantitativa, resulta conveniente distinguir dos grandes tipos de diseños: la _**investigación experimental**_ y la _**investigación observacional**_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fuentes\n",
    "\n",
    "- [_What is a Variable?_ - Statistics By Jim](https://statisticsbyjim.com/basics/what-is-a-variable/)\n",
    "- [_Independent and Dependent Variables: Differences & Examples_ - Statistics By Jim](hhttps://statisticsbyjim.com/regression/independent-dependent-variables/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
